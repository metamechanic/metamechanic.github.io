blog::
authors:: [[Buster Benson]] 
year:: 2016
url:: https://betterhumans.pub/cognitive-bias-cheat-sheet-55a472476b18
tags:: blog, reference, #bias #[[cognitive bias]] 
project:: 
public:: true

-
- ## An organized list of cognitive biases because thinking is hard.
-
- **_2022 update (1.7 million reads later 😱)_**_: The obsession that began with this post has turned into a book titled_ [_Why Are We Yelling? — The Art of Productive Disagreement_](https://amzn.to/2XxAlRq)_, because it’s in disagreement and conflict that our biases tend to shine brightest. A follow-up post that explores what we should do about our bias, once we’re interested in doing so, is here:_ [_What Can We Do About Our Bias?_](https://betterhumans.pub/what-can-we-do-about-our-bias-73c16eeb7dca)
- I’ve spent many years referencing [Wikipedia’s list of cognitive biases](https://en.wikipedia.org/wiki/List_of_cognitive_biases) whenever I have a hunch that a certain type of thinking is an official bias but I can’t recall the name or details. It’s been an invaluable reference for helping me identify the hidden flaws in my own thinking. Nothing else I’ve come across seems to be both as comprehensive and as succinct.
- However, honestly, the Wikipedia page is a bit of a tangled mess. Despite trying to absorb the information of this page many times over the years, very little of it seems to stick. I often scan it and feel like I’m not able to find the bias I’m looking for, and then quickly forget what I’ve learned. I think this has to do with how the page has organically evolved over the years. Today, it groups 175 biases into vague categories (decision-making biases, social biases, memory errors, etc) that don’t really feel mutually exclusive to me, and then lists them alphabetically within categories. There are duplicates a-plenty, and many similar biases with different names, scattered willy-nilly.
- I’ve taken some time over the last four weeks (I’m on paternity leave) to try to more deeply absorb and understand this list, and to try to come up with a simpler, clearer organizing structure to hang these biases off of. Reading deeply about various biases has given my brain something to chew on while I bounce little Louie to sleep.
- I started with the raw list of the 175 biases and added them all to a spreadsheet, then took another pass removing duplicates, and grouping similar biases (like bizarreness effect and humor effect) or complementary biases (like optimism bias and pessimism bias). The list came down to about 20 unique biased mental strategies that we use for very specific reasons.
- I made several different attempts to try to group these 20 or so at a higher level, and eventually landed on grouping them by the general mental problem that they were attempting to address. Every cognitive bias is there for a reason — primarily to save our brains time or energy. If you look at them by the problem they’re trying to solve, it becomes a lot easier to understand why they exist, how they’re useful, and the trade-offs (and resulting mental errors) that they introduce.
- ## Four problems that biases help us address:
  
  > Information overload, lack of meaning, the need to act fast, and figuring out what needs to be remembered for later.
- ## **Problem 1: Too much information.**
	- There is just too much information in the world, we have no choice but to filter almost all of it out. Our brain uses a few simple tricks to pick out the bits of information that are most likely going to be useful in some way.
	- **We notice things that are already primed in memory or repeated often.** This is the simple rule that our brains are more likely to notice things that are related to stuff that’s recently been loaded in memory.  
	    See: [_Availability heuristic_](https://en.wikipedia.org/wiki/Availability_heuristic)_,_ [_Attentional bias_](https://en.wikipedia.org/wiki/Attentional_bias)_,_ [_Illusory truth effect_](https://en.wikipedia.org/wiki/Illusory_truth_effect)_,_ [_Mere exposure effect_](https://en.wikipedia.org/wiki/Mere-exposure_effect)_,_ [_Context effect, Cue-dependent forgetting, Mood-congruent memory bias_](https://en.wikipedia.org/wiki/Cue-dependent_forgetting)_,_ [_Frequency illusion, Baader-Meinhof Phenomenon_](http://rationalwiki.org/wiki/Frequency_illusion)_,_ [_Empathy gap_](https://en.wikipedia.org/wiki/Empathy_gap)
	- **Bizarre/funny/visually-striking/anthropomorphic things stick out more than non-bizarre/unfunny things.** Our brains tend to boost the importance of things that are unusual or surprising. Alternatively, we tend to skip over information that we think is ordinary or expected.  
	    See: [_Bizarreness effect, Humor effect_](https://en.wikipedia.org/wiki/Bizarreness_effect)_,_ [_Von Restorff effect_](https://en.wikipedia.org/wiki/Von_Restorff_effect)_,_ [_Negativity bias_](https://en.wikipedia.org/wiki/Negativity_bias)_,_ [_Publication bias_](https://en.wikipedia.org/wiki/Publication_bias)_,_ [_Omission bias_](https://en.wikipedia.org/wiki/Omission_bias)
	- **We notice when something has changed.** And we’ll generally tend to weigh the significance of the new value by the direction the change happened (positive or negative) more than re-evaluating the new value as if it had been presented alone. Also applies to when we compare two similar things.See: [_Anchoring, Contrast effect, Focusing effect_](https://en.wikipedia.org/wiki/Anchoring)_,_ [_Framing effect_](https://en.wikipedia.org/wiki/Framing_effect_%28psychology%29)_,_ [_Weber–Fechner law_](https://en.wikipedia.org/wiki/Weber%E2%80%93Fechner_law)_,_ [_Distinction bias_](https://en.wikipedia.org/wiki/Distinction_bias)
	- **We are drawn to details that confirm our own existing beliefs.** This is a big one. As is the corollary: we tend to ignore details that contradicts our own beliefs.See: [_Confirmation bias_](https://en.wikipedia.org/wiki/Confirmation_bias)_,_ [_Congruence bias_](https://en.wikipedia.org/wiki/Congruence_bias)_,_ [_Post-purchase rationalization, Choice-supportive bias_](https://en.wikipedia.org/wiki/Choice-supportive_bias)_,_ [_Selective perception_](https://en.wikipedia.org/wiki/Selective_perception)_,_ [_Observer-expectancy effect, Experimenter’s bias, Observer effect, Expectation bias_](https://en.wikipedia.org/wiki/Observer-expectancy_effect)_,_ [_Ostrich effect_](https://en.wikipedia.org/wiki/Ostrich_effect)_,_ [_Subjective validation_](https://en.wikipedia.org/wiki/Subjective_validation)_,_ [_Continued influence effect_](https://en.wikipedia.org/wiki/Confirmation_bias#continued_influence_effect)_,_ [_Semmelweis reflex_](https://en.wikipedia.org/wiki/Semmelweis_reflex)_,_ [_Bucket error_](https://www.lesswrong.com/posts/EEv9JeuY5xfuDDSgF/flinching-away-from-truth-is-often-about-protecting-the)_,_ [_Law of narrative gravity_](https://www.wired.com/2017/03/the-invisible-force-that-warps-what-you-read-in-the-news/)
	- **We notice flaws in others more easily than flaws in ourselves.** Yes, before you see this entire article as a list of quirks that compromise how other people think, realize that you are also subject to these biases.See: [_Bias blind spot_](https://en.wikipedia.org/wiki/Bias_blind_spot)_,_ [_Naïve cynicism_](https://en.wikipedia.org/wiki/Na%C3%AFve_cynicism)_,_ [_Naïve realism_](https://en.wikipedia.org/wiki/Na%C3%AFve_realism_%28psychology%29)
- ## **Problem 2: Not enough meaning.**
	- The world is very confusing, and we end up only seeing a tiny sliver of it, but we need to make some sense of it in order to survive. Once the reduced stream of information comes in, we connect the dots, fill in the gaps with stuff we already think we know, and update our mental models of the world.
	- **We find stories and patterns even in sparse data.** Since we only get a tiny sliver of the world’s information, and also filter out almost everything else, we never have the luxury of having the full story. This is how our brain reconstructs the world to feel complete inside our heads.  
	    See: [_Confabulation_](https://en.wikipedia.org/wiki/Confabulation)_,_ [_Clustering illusion_](https://en.wikipedia.org/wiki/Clustering_illusion)_,_ [_Insensitivity to sample size_](https://en.wikipedia.org/wiki/Insensitivity_to_sample_size)_,_ [_Neglect of probability_](https://en.wikipedia.org/wiki/Neglect_of_probability)_,_ [_Anecdotal fallacy_](https://yourlogicalfallacyis.com/anecdotal)_,_ [_Illusion of validity_](https://en.wikipedia.org/wiki/Illusion_of_validity)_,_ [_Masked man fallacy_](https://en.wikipedia.org/wiki/Masked-man_fallacy)_,_ [_Recency illusion_](https://en.wikipedia.org/wiki/Recency_illusion)_,_ [_Gambler’s fallacy_](https://en.wikipedia.org/wiki/Gambler%27s_fallacy)_,_ [_Hot-hand fallacy_](https://en.wikipedia.org/wiki/Hot-hand_fallacy)_,_ [_Illusory correlation_](https://en.wikipedia.org/wiki/Illusory_correlation)_,_ [_Pareidolia_](https://en.wikipedia.org/wiki/Pareidolia)_,_ [_Anthropomorphism_](https://en.wikipedia.org/wiki/Anthropomorphism#Psychology_of_anthropomorphism)
	- **We fill in characteristics from stereotypes, generalities, and prior histories whenever there are new specific instances or gaps in information.** When we have partial information about a specific thing that belongs to a group of things we are pretty familiar with, our brain has no problem filling in the gaps with best guesses or what other trusted sources provide. Conveniently, we then forget which parts were real and which were filled in.See: [_Group attribution error_](https://en.wikipedia.org/wiki/Group_attribution_error)_,_ [_Ultimate attribution error_](https://en.wikipedia.org/wiki/Ultimate_attribution_error)_,_ [_Stereotyping_](https://en.wikipedia.org/wiki/Stereotype)_,_ [_Essentialism_](https://en.wikipedia.org/wiki/Essentialism)_,_ [_Functional fixedness_](https://en.wikipedia.org/wiki/Functional_fixedness)_,_ [_Moral credential effect_](https://en.wikipedia.org/wiki/Moral_credential_effect)_,_ [_Just-world hypothesis_](https://en.wikipedia.org/wiki/Just-world_hypothesis)_,_ [_Argument from fallacy_](https://en.wikipedia.org/wiki/Argument_from_fallacy)_,_ [_Authority bias_](https://en.wikipedia.org/wiki/Authority_bias)_,_ [_Automation bias_](https://en.wikipedia.org/wiki/Automation_bias)_,_ [_Bandwagon effect_](https://en.wikipedia.org/wiki/Bandwagon_effect)_,_ [_Placebo effect_](https://en.wikipedia.org/wiki/Placebo)
	- **We imagine things and people we’re familiar with or fond of as better than things and people we aren’t familiar with or fond of.** Similar to the above but the filled-in bits generally also include built in assumptions about the quality and value of the thing we’re looking at.See: [_Halo effect_](https://en.wikipedia.org/wiki/Halo_effect)_,_ [_In-group bias_](https://en.wikipedia.org/wiki/In-group_favoritism)_,_ [_Out-group homogeneity bias_](https://en.wikipedia.org/wiki/Out-group_homogeneity)_,_ [_Cross-race effect_](https://en.wikipedia.org/wiki/Cross-race_effect)_,_ [_Cheerleader effect_](https://en.wikipedia.org/wiki/Cheerleader_effect)_,_ [_Well-traveled road effect_](https://en.wikipedia.org/wiki/Well_travelled_road_effect)_,_ [_Not invented here_](https://en.wikipedia.org/wiki/Not_invented_here)_,_ [_Reactive devaluation_](https://en.wikipedia.org/wiki/Reactive_devaluation)_,_ [_Positivity effect_](https://en.wikipedia.org/wiki/Positivity_effect)
	- **We simplify probabilities and numbers to make them easier to think about.** Our subconscious mind is terrible at math and generally gets all kinds of things wrong about the likelihood of something happening if any data is missing.See: [_Mental accounting_](https://en.wikipedia.org/wiki/Mental_accounting)_,_ [_Normalcy bias_](https://en.wikipedia.org/wiki/Normalcy_bias)_,_ [_Appeal to probability fallacy_](https://en.wikipedia.org/wiki/Appeal_to_probability)_, ,_ [_Base rate fallacy_](https://en.wikipedia.org/wiki/Base_rate_fallacy)_,_ [_Murphy’s law_](https://en.wikipedia.org/wiki/Murphy%27s_law)_,_ [_Hofstadter’s law_](https://en.m.wikipedia.org/wiki/Hofstadter%27s_law)_,_ [_Subadditivity effect_](https://en.wikipedia.org/wiki/Subadditivity_effect)_,_ [_Survivorship bias_](https://en.wikipedia.org/wiki/Survivorship_bias)_,_ [_Zero sum bias_](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3153800/)_,_ [_Denomination effect_](https://en.wikipedia.org/wiki/Denomination_effect)_,_ [_Magic number 7+-2_](https://en.wikipedia.org/wiki/The_Magical_Number_Seven,_Plus_or_Minus_Two)_,_ [_Swimmer’s body illusion_](http://jesusgilhernandez.com/2013/12/05/the-swimmers-body-illusion/)_,_ [_Money illusion_](https://en.wikipedia.org/wiki/Money_illusion)_,_ [_Conservatism_](https://en.wikipedia.org/wiki/Conservatism_%28belief_revision%29)
	- **We think we know what others are thinking.** In some cases this means that we assume that they know what we know, in other cases we assume they’re thinking about us as much as we are thinking about ourselves. It’s basically just a case of us modeling their own mind after our own (or in some cases after a much less complicated mind than our own).  
	    See: [_Curse of knowledge_](https://en.wikipedia.org/wiki/Curse_of_knowledge)_,_ [_Illusion of transparency_](https://en.wikipedia.org/wiki/Illusion_of_transparency)_,_ [_Spotlight effect, Streetlight effect_](https://en.wikipedia.org/wiki/Spotlight_effect)_,_ [_Illusion of external agency_](https://en.wikipedia.org/wiki/Illusion_of_external_agency)_,_ [_Illusion of asymmetric insight_](https://en.wikipedia.org/wiki/Illusion_of_asymmetric_insight)_,_ [_Extrinsic incentive error_](https://en.wikipedia.org/wiki/Extrinsic_incentives_bias)
	- **We project our current mindset and assumptions onto the past and future.** Magnified also by the fact that we’re not very good at imagining how quickly or slowly things will happen or change over time.  
	    See: [_Hindsight bias_](https://en.wikipedia.org/wiki/Hindsight_bias)_,_ [_Outcome bias_](https://en.wikipedia.org/wiki/Outcome_bias)_,_ [_Moral luck_](https://en.wikipedia.org/wiki/Moral_luck)_,_ [_Declinism_](https://en.wikipedia.org/wiki/Declinism)_,_ [_Telescoping effect_](https://en.wikipedia.org/wiki/Telescoping_effect)_,_ [_Rosy retrospection_](https://en.wikipedia.org/wiki/Rosy_retrospection)_,_ [_Impact bias_](https://en.wikipedia.org/wiki/Impact_bias)_,_ [_Pessimism bias_](https://en.wikipedia.org/wiki/Optimism_bias#Pessimism_bias)_,_ [_Planning fallacy_](https://en.wikipedia.org/wiki/Planning_fallacy)_,_ [_Time-saving bias_](https://en.wikipedia.org/wiki/Time-saving_bias)_,_ [_Pro-innovation bias_](https://en.wikipedia.org/wiki/Pro-innovation_bias)_,_ [_Projection bias_](https://en.wikipedia.org/wiki/Affective_forecasting#Projection_bias)_,_ [_Restraint bias_](https://en.wikipedia.org/wiki/Restraint_bias)_,_ [_Self-consistency bias_](https://psychlopedia.wikispaces.com/self-consistency+bias)
- ## **Problem 3: Need to act fast.**
  collapsed:: true
	- We’re constrained by time and information, and yet we can’t let that paralyze us. Without the ability to act fast in the face of uncertainty, we surely would have perished as a species long ago. With every piece of new information, we need to do our best to assess our ability to affect the situation, apply it to decisions, simulate the future to predict what might happen next, and otherwise act on our new insight.
	- **In order to act, we need to be confident in our ability to make an impact and to feel like what we do is important.** In reality, most of this confidence can be classified as overconfidence, but without it we might not act at all.  
	    See: [_Overconfidence effect_](https://en.wikipedia.org/wiki/Overconfidence_effect)_,_ [_Egocentric bias_](https://en.wikipedia.org/wiki/Egocentric_bias)_,_ [_Optimism bias_](https://en.wikipedia.org/wiki/Optimism_bias)_,_ [_Social desirability bias_](https://en.wikipedia.org/wiki/Social_desirability_bias)_,_ [_Third-person effect_](https://en.wikipedia.org/wiki/Third-person_effect)_,_ [_Forer effect, Barnum effect_](https://en.wikipedia.org/wiki/Barnum_effect)_,_ [_Illusion of control_](https://en.wikipedia.org/wiki/Illusion_of_control)_,_ [_False consensus effect_](https://en.wikipedia.org/wiki/False-consensus_effect)_,_ [_Dunning-Kruger effect_](https://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect)_,_ [_Hard-easy effect_](https://en.wikipedia.org/wiki/Hard%E2%80%93easy_effect)_,_ [_Illusory superiority_](https://en.wikipedia.org/wiki/Illusory_superiority)_,_ [_Lake Wobegone effect_](https://en.wikipedia.org/wiki/Lake_Wobegon#The_Lake_Wobegon_effect)_,_ [_Self-serving bias_](https://en.wikipedia.org/wiki/Self-serving_bias)_,_ [_Actor-observer bias, Fundamental attribution error_](https://en.wikipedia.org/wiki/Fundamental_attribution_error)_,_ [_Defensive attribution hypothesis_](https://en.wikipedia.org/wiki/Defensive_attribution_hypothesis)_,_ [_Trait ascription bias_](https://en.wikipedia.org/wiki/Trait_ascription_bias)_,_ [_Effort justification_](https://en.wikipedia.org/wiki/Effort_justification)_,_ [_Risk compensation, Peltzman effect_](https://en.wikipedia.org/wiki/Risk_compensation)_,_ [_Armchair fallacy_](http://www.elischiff.com/blog/2015/2/4/criticism-and-the-armchair-fallacy)
	- **In order to stay focused, we favor the immediate, relatable thing in front of us over the delayed and distant.** We value stuff more in the present than in the future, and relate more to stories of specific individuals than anonymous individuals or groups. I’m surprised there aren’t more biases found under this one, considering how much it impacts how we think about the world.See: [_Hyperbolic discounting_](https://en.wikipedia.org/wiki/Hyperbolic_discounting)_,_ [_Appeal to novelty_](https://en.wikipedia.org/wiki/Appeal_to_novelty)_,_ [_Identifiable victim effect_](https://en.wikipedia.org/wiki/Identifiable_victim_effect)
	- **In order to get anything done, we’re motivated to complete things that we’ve already invested time and energy in.** The behavioral economist’s version of Newton’s first law of motion: an object in motion stays in motion. This helps us finish things, even if we come across more and more reasons to give up.See: [_Sunk cost fallacy_](https://en.wikipedia.org/wiki/Sunk_costs)_,_ [_Irrational escalation, Escalation of commitment_](https://en.wikipedia.org/wiki/Escalation_of_commitment)_,_ [_Loss aversion_](https://en.wikipedia.org/wiki/Loss_aversion)_,_ [_IKEA effect, Processing difficulty effect_](https://en.wikipedia.org/wiki/IKEA_effect)_,_ [_Generation effect_](https://en.wikipedia.org/wiki/Generation_effect)_,_ [_Zero-risk bias_](https://en.wikipedia.org/wiki/Zero-risk_bias)_,_ [_Disposition effect_](https://en.wikipedia.org/wiki/Disposition_effect)_,_ [_Unit bias_](http://www.alleydog.com/glossary/definition.php?term=Unit+Bias)_,_ [_Pseudocertainty effect_](https://en.wikipedia.org/wiki/Pseudocertainty_effect)_,_ [_Endowment effect_](https://en.wikipedia.org/wiki/Endowment_effect)_,_ [_Backfire effect_](https://en.wikipedia.org/wiki/Confirmation_bias#backfire_effect)
	- **In order to avoid mistakes, we’re motivated to preserve our autonomy and status in a group, and to avoid irreversible decisions.** If we must choose, we tend to choose the option that is perceived as the least risky or that preserves the status quo. Better the devil you know than the devil you do not.See: [_System justification,_](https://en.wikipedia.org/wiki/System_justification) [_Reactance_](https://en.wikipedia.org/wiki/Reactance_(psychology))_,_ [_Reverse psychology_](https://en.wikipedia.org/wiki/Reverse_psychology)_,_ [_Decoy effect_](https://en.wikipedia.org/wiki/Decoy_effect)_,_ [_Social comparison bias_](https://en.wikipedia.org/wiki/Social_comparison_bias)_,_ [_Status quo bias_](https://en.wikipedia.org/wiki/Status_quo_bias)_,_ [_Abilene paradox_](https://en.wikipedia.org/wiki/Abilene_paradox)_,_ [_Law of the instrument, Law of the hammer, Maslow’s hammer, Golden hammer_](https://en.m.wikipedia.org/wiki/Law_of_the_instrument)_,_ [_Chesterton’s fence_](https://en.m.wikipedia.org/wiki/Wikipedia:Chesterton's_fence)_,_ [_Hippo problem_](https://velvetchainsaw.com/2011/06/14/hippo-room-not-your-audience/)
	- **We favor options that appear simple or that have more complete information over more complex, ambiguous options.** We’d rather do the quick, simple thing than the important complicated thing, even if the important complicated thing is ultimately a better use of time and energy.See: [_Ambiguity bias_](https://en.wikipedia.org/wiki/Ambiguity_effect)_,_ [_Information bias_](https://en.wikipedia.org/wiki/Information_bias_(psychology))_,_ [_Belief bias_](https://en.wikipedia.org/wiki/Belief_bias)_,_ [_Rhyme as reason effect_](https://en.wikipedia.org/wiki/Rhyme-as-reason_effect)_,_ [_Bike-shedding effect, Law of Triviality_](https://en.wikipedia.org/wiki/Law_of_triviality)_,_ [_Delmore effect_](http://www-psych.stanford.edu/~wit/abstract.html)_,_ [_Conjunction fallacy_](https://en.wikipedia.org/wiki/Conjunction_fallacy)_,_ [_Occam’s razor_](https://en.wikipedia.org/wiki/Occam%27s_razor)_,_ [_Less-is-better effect_](https://en.wikipedia.org/wiki/Less-is-better_effect)_,_ [_Sapir-Whorf-Korzybski hypothesis_](http://www.nobeliefs.com/Sapir-Whorf-Korzybski.htm)
- ## **Problem 4: What should we remember?**
  collapsed:: true
	- There’s too much information in the universe. We can only afford to keep around the bits that are most likely to prove useful in the future. We need to make constant bets and trade-offs around what we try to remember and what we forget. For example, we prefer generalizations over specifics because they take up less space. When there are lots of irreducible details, we pick out a few standout items to save and discard the rest. What we save here is what is most likely to inform our filters related to problem 1’s information overload, as well as inform what comes to mind during the processes mentioned in problem 2 around filling in incomplete information. It’s all self-reinforcing.
	- **We edit and reinforce some memories after the fact.** During that process, memories can become stronger, however various details can also get accidentally swapped. We sometimes accidentally inject a detail into the memory that wasn’t there before.See: [_Misattribution of memory, Source confusion_](https://en.wikipedia.org/wiki/Misattribution_of_memory)_,_ [_Cryptomnesia_](https://en.wikipedia.org/wiki/Cryptomnesia)_,_ [_False memory_](https://en.wikipedia.org/wiki/Confabulation)_,_ [_Suggestibility_](https://en.wikipedia.org/wiki/Suggestibility#External)_,_ [_Spacing effect_](https://en.wikipedia.org/wiki/Spacing_effect)
	- **We discard specifics to form generalities.** We do this out of necessity, but the impact of implicit associations, stereotypes, and prejudice results in some of the most glaringly bad consequences from our full set of cognitive biases.See: [_Implicit associations, Implicit stereotypes, Stereotypical bias_](https://en.wikipedia.org/wiki/Implicit_stereotype)_,_ [_Prejudice_](https://en.wikipedia.org/wiki/Prejudice)_,_ [_Fading affect bias_](https://en.wikipedia.org/wiki/Fading_affect_bias)
	- **We reduce events and lists to their key elements.** It’s difficult to reduce events and lists to generalities, so instead we pick out a few items to represent the whole.See: [_Peak–end rule_](https://en.wikipedia.org/wiki/Peak%E2%80%93end_rule)_,_ [_Leveling and sharpening_](https://en.wikipedia.org/wiki/Leveling_and_sharpening)_,_ [_Misinformation effect_](https://en.wikipedia.org/wiki/Misinformation_effect)_,_ [_Duration neglect_](https://en.wikipedia.org/wiki/Duration_neglect)_,_ [_Serial recall effect, List-length effect_](https://en.wikipedia.org/wiki/Recall_%28memory%29#Serial_recall)_,_ [_Modality effect_](https://en.wikipedia.org/wiki/Modality_effect)_,_ [_Memory inhibition, Part-list cueing effect_](https://en.wikipedia.org/wiki/Memory_inhibition)_,_ [_Primacy effect_](https://en.wikipedia.org/wiki/Serial_position_effect#Primacy_effect)_,_ [_Recency effect_](https://en.wikipedia.org/wiki/Serial_position_effect#Recency_effect)_,_ [_Serial position effect_](https://en.wikipedia.org/wiki/Serial_position_effect)_,_ [_Suffix effect_](https://coglab.cengage.com/labs/suffix_effect.shtml)
	- **We store memories differently based on how they were experienced.** Our brains will only encode information that it deems important at the time, but this decision can be affected by other circumstances (what else is happening, how is the information presenting itself, can we easily find the information again if we need to, etc) that have little to do with the information’s value.See: [_Picture superiority effect_](https://en.wikipedia.org/wiki/Picture_superiority_effect)_,_ [_Levels of processing effect_](https://en.wikipedia.org/wiki/Levels-of-processing_effect), [_Testing effect_](https://en.wikipedia.org/wiki/Testing_effect)_,_ [_Absent-mindedness_](https://en.wikipedia.org/wiki/Absent-mindedness)_,_ [_Next-in-line effect_](http://www.oxfordreference.com/view/10.1093/oi/authority.20110803100232913)_,_ [_Tip of the tongue phenomenon_](https://en.wikipedia.org/wiki/Tip_of_the_tongue)_,_ [_Google effect_](https://en.wikipedia.org/wiki/Google_effect)_,_ [_Self-relevance effect_](https://en.wikipedia.org/wiki/Self-reference_effect)
- ## Great, how am I supposed to remember all of this?
	- You don’t have to. But you can start by remembering these four giant problems our brains have evolved to deal with over the last few million years (and maybe bookmark this page if you want to occasionally reference it for the exact bias you’re looking for):
		- logseq.order-list-type:: number
		  1.  Information overload sucks, so we aggressively filter. Noise becomes signal.
		- logseq.order-list-type:: number
		  2.  Lack of meaning is confusing, so we fill in the gaps. Signal becomes a story.
		- logseq.order-list-type:: number
		  3.  Need to act fast lest we lose our chance, so we jump to conclusions. Stories become decisions.
		- logseq.order-list-type:: number
		  4.  This isn’t getting easier, so we try to remember the important bits. Decisions inform our mental models of the world.
	- In order to avoid drowning in ** [[information overload]] **, our brains need to skim and filter insane amounts of information and quickly, almost effortlessly, decide which few things in that firehose are actually important and call those out.
	- In order to **construct meaning** out of the bits and pieces of information that come to our attention, we need to fill in the gaps, and map it all to our existing mental models. In the meantime we also need to make sure that it all stays relatively stable and as accurate as possible.
	- In order to **act fast**, our brains need to make split-second decisions that could impact our chances for survival, security, or success, and feel confident that we can make things happen.
	- And in order to keep doing all of this as efficiently as possible, our brains need to **remember the most important and useful bits** of new information and inform the other systems so they can adapt and improve over time, but no more than that.
- ## Sounds pretty useful! So what’s the downside?
  
  In addition to the four problems, it would be useful to remember these four truths about how our solutions to these problems have problems of their own:
  
  1.  **We don’t see everything.** Some of the information we filter out is actually useful and important.
  2.  **Our search for meaning can conjure illusions.** We sometimes imagine details that were filled in by our assumptions, and construct meaning and stories that aren’t really there.
  3.  **Quick decisions can be seriously flawed.** Some of the quick reactions and decisions we jump to are unfair, self-serving, and counter-productive.
  4.  **Our memory reinforces errors.** Some of the stuff we remember for later just makes all of the above systems more biased, and more damaging to our thought processes.
  
  By keeping the four problems with the world and the four consequences of our brain’s strategy to solve them, the [_availability heuristic_](https://en.wikipedia.org/wiki/Availability_heuristic) (and, specifically, the [_Baader-Meinhof phenomenon_](http://rationalwiki.org/wiki/Frequency_illusion)) will ensure that we notice our own biases more often. If you visit this page to refresh your mind every once in a while, the [_spacing effect_](https://en.wikipedia.org/wiki/Spacing_effect) will help underline some of these thought patterns so that our [_bias blind spot_](https://en.wikipedia.org/wiki/Bias_blind_spot) and [_naïve realism_](https://en.wikipedia.org/wiki/Na%C3%AFve_realism_%28psychology%29) is kept in check.
  
  Nothing we do can make the 4 problems go away (until we have a way to expand our minds’ computational power and memory storage to match that of the universe) but if we accept that we are permanently biased, but that there’s room for improvement, [_confirmation bias_](https://en.wikipedia.org/wiki/Confirmation_bias) will continue to help us find evidence that supports this, which will ultimately lead us to better understanding ourselves.
  
  > "Since learning about confirmation bias, I keep seeing it everywhere!”
  
  Cognitive biases are just tools, useful in the right contexts, harmful in others. They’re the only tools we’ve got, and they’re even pretty good at what they’re meant to do. We might as well get familiar with them and even appreciate that we at least have some ability to process the universe with our mysterious brains.
  
  A couple days after posting this,
  
  asked if it would be okay to do a “diagrammatic poster remix” of it, to which I of course said YES to. Here’s what he came up with:
- ![image.png](../assets/image_1705010197436_0.png)
- ![](Cognitive%20bias%20cheat%20sheet.%20An%20organized%20list%20of%20cognitive%20biases%20because%20thinking%20is%20hard.%20%20by%20Buster%20Benson%20%20Better%20Humans/171TzKnr7bzXU_l_pU6DCNA.jpeg)
- If you feel so inclined, you can buy a poster-version of the above image [here](https://www.designhacks.co/products/cognitive-bias-codex-poster). If you want to play around with the data in JSON format, you can do that [here](https://github.com/busterbenson/public/blob/master/cognitive-bias-cheat-sheet.json).
- ## 🚀 Get more news about biases!
  
  To get notifications about progress on [the book](https://amzn.to/2XxAlRq) that is evolving out of this post, and future bias-related news, [sign up here](https://buster.substack.com/).
  
  I’ll leave you with the first part of this little poem by Emily Dickinson:
  
  > The Brain — is wider — than the Sky  
  > For — put them side by side —  
  > The one the other will contain  
  > With ease — and You — beside —